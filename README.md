# SynEthica: Agentic Responsible AI Data Generator

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/release/python-3100/)
[![Powered by Gemini](https://img.shields.io/badge/AI-Google_Gemini-4285F4?logo=google)](https://deepmind.google/technologies/gemini/)
[![LangGraph](https://img.shields.io/badge/Orchestration-LangGraph-orange)](https://langchain-ai.github.io/langgraph/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **Team PRIME** | *E-Summit '25 Hackathon Submission*
>
> *"Solving the Privacy-Utility-Fairness Trilemma through Autonomous Agentic Loops."*

---

## ğŸ“º Project Demo
Watch the full working demo and explanation of SynEthica on YouTube:

[![SynEthica Demo Video](https://img.youtube.com/vi/lc3LNJxmf-I/0.jpg)](https://youtu.be/lc3LNJxmf-I?si=eoxnEdqxICxO5A4l)

---

## ğŸ“– Overview

**SynEthica** is a closed-loop, agentic framework designed to generate high-quality **Synthetic Data** that is statistically realistic, privacy-safe, and devoid of demographic bias. 

Unlike traditional static generators, SynEthica employs an **Autonomous Correction Loop**. If the generated data fails specific fairness metrics (e.g., Disparate Impact Ratio) or privacy checks, our agents automatically interveneâ€”applying mitigation strategies like re-weighing or prompt-tuningâ€”and re-validate the data until it meets strict compliance standards.

---

## ğŸ—ï¸ Architecture

SynEthica operates on a **LangGraph-based Agentic Workflow**, ensuring dynamic feedback loops between generation and validation.

![SynEthica Architecture](Images/architecture%20complex.png)

### Live Working Preview
<img width="1553" height="844" alt="image" src="https://github.com/user-attachments/assets/2101cc31-4c93-46ef-b2f6-8f494990330b" />
<img width="1556" height="698" alt="image" src="https://github.com/user-attachments/assets/bebf04d3-772a-45a8-bb3a-0285da06e92a" />
 The Agentic Loop detecting bias and triggering the Correction Agent.

<img width="1563" height="855" alt="image" src="https://github.com/user-attachments/assets/7058ff0b-8545-4e9d-a09b-ba394744973c" />
 Final auditable report generated by the QA Agent.

---

## ğŸš€ Key Features

* **ğŸ•µï¸â™‚ï¸ Automated Profiling:** Instantly analyzes raw sensitive data for schema, distribution, and inherent bias using `Input Validation Agent`.
* **ğŸ¤– Agentic Orchestration:** Built on **LangGraph**, enabling a non-linear workflow where agents can "decide" to loop back and fix data flaws.
* **âš–ï¸ Bias Mitigation:** Integrated with **AIF360** logic to detect and correct unfairness (e.g., ensuring equal loan approval rates across gender).
* **ğŸ”’ Differential Privacy Ready:** Implements privacy budgeting ($\epsilon$) concepts to ensure no individual record can be re-identified.
* **ğŸ§  Hybrid Core:** Combines **SDV (TVAE)** for tabular fidelity with **Google Gemini API** for context-aware data synthesis.

---

## ğŸ› ï¸ Tech Stack

* **Language:** Python
* **GenAI Model:** Google Gemini 1.5 Flash / Pro (via `google-genai` SDK)
* **Orchestration:** LangChain & LangGraph (Stateful Agentic Workflow)
* **Data Manipulation:** Pandas, NumPy
* **Fairness Metrics:** AIF360 (IBM), Fairlearn
* **Privacy:** Differential Privacy (Laplace Mechanism logic)

---

## ğŸ“‚ Directory Structure

```bash
SynEthica/
â”œâ”€â”€ agents/                 # Agent definitions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ profiler_agent.py   # Analyzes input data
â”‚   â”œâ”€â”€ generator_agent.py  # Interfaces with Gemini API
â”‚   â”œâ”€â”€ auditor_agent.py    # Checks Bias & Privacy metrics
â”‚   â””â”€â”€ corrector_agent.py  # Decides mitigation strategies
â”œâ”€â”€ data/                   # Data storage
â”‚   â”œâ”€â”€ input/              # Raw sensitive data (ignored in git)
â”‚   â””â”€â”€ output/             # Final synthetic datasets & reports
â”œâ”€â”€ utils/                  # Helper functions
â”‚   â”œâ”€â”€ metrics.py          # Math for DIR, Privacy Score, etc.
â”‚   â””â”€â”€ privacy_tools.py    # Noise injection utilities
â”œâ”€â”€ Images/                 # Architecture & Demo Screenshots
â”‚   â”œâ”€â”€ architecture complex.png
â”‚   â”œâ”€â”€ loop_action.png
â”‚   â””â”€â”€ final_output.png
â”œâ”€â”€ .env                    # API Keys (GEMINI_API_KEY)
â”œâ”€â”€ .gitignore              # Standard Python gitignore
â”œâ”€â”€ main.py                 # Entry point (LangGraph execution)
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ state.py                # Defines the LangGraph State Schema

```

## âš¡ Quick Start

1. **Clone the Repository**
```bash
git clone [https://github.com/debanganghosh08/SynEthica.git](https://github.com/debanganghosh08/SynEthica.git)
cd SynEthica

```


2. **Set up Environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

```


3. **Configure Credentials**
Create a `.env` file in the root directory:
```env
GEMINI_API_KEY=your_google_api_key_here

```


4. **Run the Pipeline**
Place your input CSV in `data/input/` and run:
```bash
python main.py
